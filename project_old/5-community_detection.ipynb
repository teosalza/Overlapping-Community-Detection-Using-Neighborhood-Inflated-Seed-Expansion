{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community detection\n",
    "\n",
    "In this notebook we will use a well known library for graph analysis, which includes also algorithm for community detection. The aim is to become familiar with these type of tools, so that to be able to combine them when solving a problem.\n",
    "\n",
    "The (Python) library is called NetworkX: information about such a library can be found at:\n",
    "\n",
    "https://networkx.org/\n",
    "\n",
    "The detailed documentation, including a tutorial and the reference tot he different algorithms and fucntions, can be found at:\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/index.html\n",
    "\n",
    "The library can be installed using pip:\n",
    "\n",
    "```python\n",
    "pip install networkx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic notions\n",
    "\n",
    "NetworkX handles graphs that are undirected or directed, and the type is implicitly declared since we need to use different constructors.\n",
    "\n",
    "Graphs can be crated starting from a dataset stored in a Python data structure, such as the adjacency list (dictionary, where the key is the node id and the value is a list with the nighbor ids), or the list edges.\n",
    "\n",
    "To load the data, we use the same fuction defined in the PageRank notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    input_lines = []\n",
    "    raw_lines = open(filename, 'r').read().splitlines()\n",
    "    num_nodes = 0\n",
    "    nodes = {}\n",
    "    for line in raw_lines:\n",
    "        line_content = line.split()\n",
    "        from_id = int(line_content[0])\n",
    "        to_id = int(line_content[1])\n",
    "        if from_id not in nodes:\n",
    "            nodes[from_id] = num_nodes\n",
    "            num_nodes += 1\n",
    "        if to_id not in nodes:\n",
    "            nodes[to_id] = num_nodes\n",
    "            num_nodes += 1\n",
    "        input_lines.append([nodes[from_id], nodes[to_id]])\n",
    "    return input_lines, num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file containing a toy example is called \"5-toy_example.txt\".\n",
    "\n",
    "Let's load our dataset, and create the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from networkx.algorithms.community import modularity\n",
    "\n",
    "input_file = \"./5-toy_example.txt\"\n",
    "\n",
    "input_edges, num_nodes = load_data(input_file)\n",
    "\n",
    "# we create an undirected graph from the dataset\n",
    "toy_graph = nx.Graph(input_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we draw it (in case of a warning, re-run the cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(toy_graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a directed graph from the same dataset (note the link between node 3 and 7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_graph_dir = nx.DiGraph(input_edges)\n",
    "nx.draw(toy_graph_dir, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take your time to explore the available algorithms and functions offered by the NetworkX library at: \n",
    "\n",
    "https://networkx.org/documentation/stable/reference/functions.html\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/algorithms/index.html\n",
    "\n",
    "For instance, given a graph $G$, the function ```degree_histogram(G)``` provides the empirical degree distribution. Given a source node A, the algorithm ```shortest_path(G, A)``` computes the shortest path from A to any other nodes $\\in G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q1\n",
    "<div class=\"alert alert-info\">\n",
    "One of the avilable algorithms (see \"Link Analysis\") is PageRank. Consider the graph provided in the PageRank lab (\"4-email-Eu-core.txt\"), compute the PageRank with the NetworkX library and compare the results with the implementation done in the previous lab.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding communities\n",
    "\n",
    "We have already imported the implmenetation of the Girvan-Newman algorithm, so we can obtain the communities with a simple call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = list(girvan_newman(toy_graph))\n",
    "\n",
    "# print the communities at each level\n",
    "lev = 0\n",
    "for comm in communities:\n",
    "    print(\"level\", lev, \":\", comm)\n",
    "    lev += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the communities at two different levels. In particular, at level 0 (2 communities), level 1 (3 communities) and level 2 (4 communities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 0 - there are 2 communities\n",
    "color_map = ['red']*len(toy_graph.nodes)\n",
    "for node in communities[0][0]:\n",
    "    color_map[node] = 'blue'\n",
    "    \n",
    "nx.draw(toy_graph, node_color=color_map, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1 - there are 3 communities\n",
    "color_map = ['red']*len(toy_graph.nodes)\n",
    "for node in communities[1][0]:\n",
    "    color_map[node] = 'blue'\n",
    "for node in communities[1][1]:\n",
    "    color_map[node] = 'green'\n",
    "    \n",
    "nx.draw(toy_graph, node_color=color_map, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 2 - there are 4 communities\n",
    "color_map = ['red']*len(toy_graph.nodes)\n",
    "for node in communities[2][0]:\n",
    "    color_map[node] = 'blue'\n",
    "for node in communities[2][1]:\n",
    "    color_map[node] = 'green'\n",
    "for node in communities[2][2]:\n",
    "    color_map[node] = 'yellow'\n",
    "    \n",
    "nx.draw(toy_graph, node_color=color_map, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the best division into communities, we use the concept of \"modularity\", which is computed by the function we imported -- it takes as input the graph and the groups into which is divided and output the modularity for that set of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_modularity = []\n",
    "for groups in communities:\n",
    "    Q_modularity.append(modularity(toy_graph, groups))\n",
    "\n",
    "# print the modularity at each level\n",
    "for i in range(len(Q_modularity)):\n",
    "    print(\"level\", i, \":\", Q_modularity[i])\n",
    "\n",
    "# plot it\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(len(communities)), Q_modularity)\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('Q - modularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our maximum modularity is found at level 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q2\n",
    "<div class=\"alert alert-info\">\n",
    "Apply the methodology described above to a more complex graph, such as \"5-large_graph.txt\"\n",
    "\n",
    "The (undirected) graph contains 200 nodes and 755 edges, and the computation may take a while.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A counter-example\n",
    "\n",
    "Not all graphs have communities, so we should be able to identify also this case. \n",
    "\n",
    "In particular:\n",
    "- The modularity does not show a clear peak;\n",
    "- The size of the communities are heterogeneous (large clusters, and very small ones).\n",
    "\n",
    "Let's see an example with a randomly generated Wattsâ€“Strogatz small-world graph -- see https://networkx.org/documentation/stable/reference/generators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "ws_graph = nx.connected_watts_strogatz_graph(30, 10, 0.8, seed=46378216)\n",
    "nx.draw(ws_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the communities\n",
    "communities = list(girvan_newman(ws_graph))\n",
    "\n",
    "# compute the modularity\n",
    "Q_modularity = []\n",
    "for groups in communities:\n",
    "    Q_modularity.append(modularity(ws_graph, groups))\n",
    "\n",
    "# plot the modularity graph\n",
    "plt.plot(np.arange(len(communities)), Q_modularity)\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('Q - modularity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the communities at level 8, we will see a lot of one-node communities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(communities[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open problem\n",
    "\n",
    "The aim of this last section is to analyze a problem with the tools seen so far. In particular, let's consider the Movielens dataset analyzed when we discussed the recommendation systems. The question is:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Can movies be clustered into groups? If so, do the movies in the same group share some common characteristics?\n",
    "</div>\n",
    "\n",
    "We do not know if we will obtain an answer to our questions, but this is part of the exploratory analysis of a dataset.\n",
    "\n",
    "The plan would be:\n",
    "1. Find a way to represent movies such that we can run a clustering algorithm;\n",
    "2. Run the clustering and check if there are groups;\n",
    "3. Analyze the movies within each group.\n",
    "\n",
    "We may be tempted to use *k-means* as clustering algorithm. This means that we need to represent each movie in a $d-$dimensional space (i.e., an *embedding*). But right now we do not have any tool to do that. \n",
    "\n",
    "Instead, we could represent the movies with an **undirected graph**. Nodes are movies, and edges represent the similarity, i.e., there is an edge between movie $i$ and $j$ if the similarity between $i$ and $j$ is above some threshold. Therefore, we need to compute the item-item similarities amonge movies, define a threshold, and build our graph.\n",
    "\n",
    "At this point, we can analyze the graph to detect if there are communities (movies that are more similar within the group), and analyze such communities.\n",
    "\n",
    "Additional notes:\n",
    "- The community detection algorithm may take up to 10 hours to analyze graphs with 1000 nodes: when building the graphs, consider only the movies with average rating above some threshold (and choose the threshold to have at most 1000 movies to work with)\n",
    "- On the Movielens website it is possibile to find additional files (associated to the dataset) that contains information about the movie title, genres and user assigned tags: the analysis of the movies of each cluster should consider these informations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
